{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DeepLandforms**\n",
    "**Running this notebook on georeferenced images with a pre-trained model will map landforms automatically landforms and create a geopackage**\n",
    "\n",
    "\n",
    "Author: giacomo.nodjoumi@hyranet.info - g.nodjoumi@jacobs-university.de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import datetime\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.catalog import Metadata\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from pyproj import CRS\n",
    "#from pycocotools import mask\n",
    "import random\n",
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import shutil\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.GenUtils import get_paths\n",
    "from utils.detectron_utils import CustomPredictor\n",
    "from utils.geoshape_utils import parallel_funcs, chunk_creator, mask2shape, pred2coco, pred2shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 with Max-Q Design'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user/DeepLandforms'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_final.pth  trained_classes.csv\n"
     ]
    }
   ],
   "source": [
    "!ls '/mnt/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION - edit befor run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "image_path = '../data'\n",
    "geopackage_name = '/Inferred_Shapes.gpkg' ## Example for HiRISE \n",
    "proj_geopackage_name = '/Inferred_Shapes_projected.gpkg' ## Example for HiRISE \n",
    "#model_path = '../data/trained_models/5+3m/model_final.pth' \n",
    "model_path = '/mnt/model/model_final.pth'\n",
    "model_yaml = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\" ## EDIT according to trained model selected\n",
    "#src_crs = CRS.from_user_input('PROJCRS[\"Equirectangular MARS\", BASEGEOGCRS[\"GCS_MARS\",DATUM[\"unnamed\",ELLIPSOID[\"unnamed\",3393833.2607584,0,LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]],PRIMEM[\"Reference meridian\",0,ANGLEUNIT[\"degree\",0.0174532925199433,ID[\"EPSG\",9122]]]],CONVERSION[\"unnamed\",METHOD[\"Equidistant Cylindrical\",ID[\"EPSG\",1028]],PARAMETER[\"Latitude of natural origin\",20,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",180,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Latitude of 1st standard parallel\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8823]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"northing\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]')\n",
    "#dst_crs = CRS.from_user_input('PROJCS[\"Equirectangular MARS\",GEOGCS[\"GCS_MARS\",DATUM[\"unnamed\",SPHEROID[\"unnamed\",3395582.0270805,0]],PRIMEM[\"Reference meridian\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Equirectangular\"],PARAMETER[\"latitude_of_origin\",10],PARAMETER[\"central_meridian\",180],PARAMETER[\"standard_parallel_1\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]')\n",
    "dst_crs = CRS.from_wkt('PROJCRS[\"Equirectangular MARS\", BASEGEOGCRS[\"GCS_MARS\", DATUM[\"unnamed\", ELLIPSOID[\"unnamed\",3396190,0, LENGTHUNIT[\"metre\",1,  ID[\"EPSG\",9001]]]], PRIMEM[\"Reference meridian\",0, ANGLEUNIT[\"degree\",0.0174532925199433,\t\tID[\"EPSG\",9122]]]], CONVERSION[\"Equidistant Cylindrical\", METHOD[\"Equidistant Cylindrical\", ID[\"EPSG\",1028]], PARAMETER[\"Latitude of 1st standard parallel\",0, ANGLEUNIT[\"degree\",0.0174532925199433], ID[\"EPSG\",8823]], PARAMETER[\"Longitude of natural origin\",180, ANGLEUNIT[\"degree\",0.0174532925199433], ID[\"EPSG\",8802]], PARAMETER[\"False easting\",0, LENGTHUNIT[\"metre\",1], ID[\"EPSG\",8806]], PARAMETER[\"False northing\",0, LENGTHUNIT[\"metre\",1], ID[\"EPSG\",8807]]], CS[Cartesian,2], AXIS[\"easting\",east, ORDER[1], LENGTHUNIT[\"metre\",1, ID[\"EPSG\",9001]]], AXIS[\"northing\",north, ORDER[2], LENGTHUNIT[\"metre\",1, ID[\"EPSG\",9001]]]]')\n",
    "#dst_crs = CRS.from_wkt('GEOGCRS[\"GCS_Mars_2000_Sphere\", DATUM[\"Mars_2000_(Sphere)\", ELLIPSOID[\"Mars_2000_Sphere_IAU_IAG\",3396190,0, LENGTHUNIT[\"metre\",1]], ID[\"ESRI\",106971]], PRIMEM[\"Reference_Meridian\",0, ANGLEUNIT[\"Degree\",0.0174532925199433]], CS[ellipsoidal,2], AXIS[\"longitude\",east, ORDER[1], ANGLEUNIT[\"Degree\",0.0174532925199433]], AXIS[\"latitude\",north, ORDER[2], ANGLEUNIT[\"Degree\",0.0174532925199433]]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(thing_classes=['Type-3',\n",
       "                         'Type-4',\n",
       "                         'Type-1a',\n",
       "                         'Crater',\n",
       "                         'Type-1b',\n",
       "                         'Type-2b',\n",
       "                         'Type-2a'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#src_crs = CRS.from_user_input(rio.open(images[0]).crs)\n",
    "\n",
    "out_dir = image_path+'/outputs'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "class_file = os.path.dirname(model_path)+'/trained_classes.csv'\n",
    "class_df = pd.read_csv(class_file)\n",
    "classes = class_df[class_df.columns[0]].tolist()\n",
    "meta = Metadata()\n",
    "meta.set(thing_classes=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_paths(image_path,'tiff')\n",
    "src_crs = CRS.from_wkt(rio.open(images[0]).crs.to_wkt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model_yaml))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =  len(classes)\n",
    "cfg.MODEL.WEIGHTS = model_path\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/outputs/Inferred_Shapes.gpkg: No such file or directory\n",
      "[Errno 2] No such file or directory: '../data/outputs/Processed.csv'\n"
     ]
    }
   ],
   "source": [
    "cols = ['Name','Class','Score']\n",
    "dst_gpkg = out_dir+'/Inferred_Shapes.gpkg'\n",
    "proc_csv = out_dir+'/Processed.csv'\n",
    "try:\n",
    "    geoshapes = gpd.read_file(dst_gpkg)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    geoshapes = gpd.GeoDataFrame(columns=cols)\n",
    "    pass\n",
    "try:\n",
    "    proc_df = pd.read_csv(proc_csv)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    proc_df = pd.DataFrame(columns=['Name','Detections'])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = list(chunk_creator(images,batch_size))\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "Generating Images:   0%|          | 0/10355 [00:00<?, ?File/s]/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Generating Images:  42%|████▏     | 4336/10355 [26:03<54:55,  1.83File/s]  "
     ]
    }
   ],
   "source": [
    "CP = CustomPredictor(cfg)\n",
    "JOBS=psutil.cpu_count(logical=False)\n",
    "with tqdm(total=len(images),\n",
    "             desc = 'Generating Images',\n",
    "             unit='File') as pbar:\n",
    "    start = datetime.now()\n",
    "    for d in range(len(chunks)):\n",
    "        chunk = list(chunks[d])\n",
    "\n",
    "        lambda_f = lambda element:element not in proc_df['Name'].to_list()\n",
    "        filtered = filter(lambda_f, chunk)\n",
    "\n",
    "        chunk = list(filtered)\n",
    "        if len(chunk)>0:\n",
    "            \n",
    "            data_dict = [{'Name': ii, 'Detections': np.nan} for ii in chunk]\n",
    "            tmp_df = pd.DataFrame.from_dict(data_dict)\n",
    "            paths = [image_path+'/'+ele for ele in chunk]\n",
    "            open_images = [rio.open(img_path) for img_path in paths]\n",
    "            imgs = [reshape_as_image(image.read()) for image in open_images]\n",
    "            predictions = CP(imgs)\n",
    "            masks = predictions[0]['instances'].pred_masks.cpu().numpy()\n",
    "            if len(masks)>0:\n",
    "                detections = []\n",
    "                for i in range(len(predictions)):\n",
    "                    gdf = pred2shape(predictions[i], paths[i], open_images[i],classes, JOBS, out_dir)    \n",
    "                    geoshapes = geoshapes.append(gdf, ignore_index=True)\n",
    "                    #cv2.imwrite(out_dir,open_images[i])\n",
    "                    shutil.copy(paths[i], out_dir+'/'+os.path.basename(paths[i]))\n",
    "                    geoshapes.to_file(dst_gpkg, driver='GPKG', crs=src_crs)     \n",
    "                    geoshapes.crs = src_crs\n",
    "                    detections.append(len(geoshapes))\n",
    "                    tmp_df['Detections']=len(geoshapes)\n",
    "                    proc_df = proc_df.append(tmp_df,ignore_index=True)\n",
    "                    proc_df.to_csv(proc_csv, index=False)\n",
    "            else:\n",
    "                tmp_df['Detections'] = 0\n",
    "                proc_df = proc_df.append(tmp_df,ignore_index=True)\n",
    "                proc_df.to_csv(proc_csv, index=False)\n",
    "\n",
    "\n",
    "        pbar.update(batch_size)\n",
    "    stop = datetime.now()\n",
    "    print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoshapes_proj= geoshapes.copy()\n",
    "geoshapes_proj.crs = dst_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoshapes_proj.to_file(out_dir+proj_geopackage_name, driver='GPKG', crs=dst_crs) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
