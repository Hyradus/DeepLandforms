{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b791e4-cc04-4b53-bcd5-fe2ddcbb283c",
   "metadata": {},
   "source": [
    "# **DeepLandforms - v2**\n",
    "\n",
    "Author: giacomo.nodjoumi@hyranet.info - g.nodjoumi@jacobs-university.de\n",
    "\n",
    "## DeepLandforms\n",
    "\n",
    "With this notebook, users can use custom [YOLOv8](https://github.com/ultralytics/ultralytics) trained models for object detection and instance segmentation models on custom dataset of georeferenced images.\n",
    "Results can be visualized directly in the noteboo using leafmap and WMS backend.\n",
    "\n",
    "The output consist of a folder containing:\n",
    "* Crop of the detections (georeferenced)\n",
    "* Label file in COCO json format for each image for segmentation\n",
    "* Label file in YOLO txt format for object detection\n",
    "* Geopackage containing a single layer with image name, confidence leve, class.\n",
    "\n",
    "## Usage\n",
    "\n",
    "* Put or link the dataset into the **DeepLandforms** *.env* file\n",
    "* Run docker-compose up\n",
    "* Edit the *configs* section by editing the following parameters:\n",
    "\n",
    "## Parameters\n",
    " ------------------------------------------------------------------\n",
    "| **Parameter** | **Description** | **Example** |\n",
    "| ---- | ---- | ---- |\n",
    "| **data_dir** | local path of the data dir |  | /home/user/data |\n",
    "| **model_path** | local path and name of the model  | /home/user/data/best.pt |\n",
    "| **sam_checkpoint** | Segment Anything checkpoint for instance segmentation | /home/user/data/sam_vit_h_4b8939.pth |\n",
    "| **dst_crs** | CRS of the final geopackage | provide as WKT or proj4 |\n",
    "| **device** | device where to run the model | cuda or cpu |\n",
    "------------------------------------------------------------------\n",
    "Then just execute the notebook and monitor the training in **Tensorboard** container.\n",
    "\n",
    "## Funding\n",
    "*This study is within the Europlanet 2024 RI and EXPLORE project, and it has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 871149 and No 101004214.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e248ab-67ef-4849-a2ca-b7c98d497ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj.crs import CRS\n",
    "dst_crs = CRS.from_wkt('GEOGCRS[\"GCS_Mars_2000\",DATUM[\"D_Mars_2000\",ELLIPSOID[\"Mars_2000_IAU_IAG\",3396190,169.894447223612,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Reference_Meridian\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Not known.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"ESRI\",104905]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b53588-e7b3-455d-8b29-55993c8e2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from utils.utils import get_paths, window_calc, mask2shape, bboxes2df, bbox2points, box2geotiff, box2sam, PlotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306f6205-16b2-4859-81f3-9bf55091a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/Giacomo/data/test'\n",
    "dst_dir = f\"{test_dir}/detections\"\n",
    "os.makedirs(dst_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f892a7fe-8558-402c-b77c-66a4f1603521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path= '/home/Giacomo/DeepLandforms/DeepLearning/DL_BACK/Notebooks/YOLO/runs/detect/yolov8x_custom_640_multiclass_10m_Augm/weights/best.pt'\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60eebfb9-7413-490c-a206-54c0cb54f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "SamAutomaticMaskGenerator, SamPredictor\n",
    "sam_checkpoint = \"/home/Giacomo/DeepLandforms/DeepLearning/segment-anything/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=\"cuda\")\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca574438-bfca-4cdb-afa0-66291d2234a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = get_paths(test_dir, 'tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f5f83a-ca1f-4af9-aa01-4a31fc4e10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Image','Class','Conf']\n",
    "geo_shape = gpd.GeoDataFrame(columns=cols)#, crs=img.crs)\n",
    "geo_points = gpd.GeoDataFrame(columns=cols)#, crs=dst_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7f4dc-9956-4e4c-b790-d253608a43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in image_list:\n",
    "    image=f\"{test_dir}/{file}\"\n",
    "    image_name, ext = os.path.splitext(os.path.basename(image))\n",
    "    \n",
    "    image_dir = os.path.dirname(image)\n",
    "    img = rio.open(image)    \n",
    "    aff = img.transform\n",
    "    width = img.width\n",
    "    height = img.height\n",
    "    img_crs = img.crs\n",
    "    results = model.predict(image, project=\"project\",name=\"prediction\")#, imgsz=1024, conf=0.6)#, iou=0.3)#, half=True)  # predict on an imagesave_crop=True, save_txt=True, save_conf=True, \n",
    "    for result in results:#\n",
    "        bboxes = np.array(result.boxes.data.cpu())\n",
    "        xywh_bboxes = np.array(result.boxes.xywhn.data.cpu())\n",
    "        classes = np.array(result.boxes.cls.data.cpu())\n",
    "        confs = np.array(result.boxes.conf.data.cpu())\n",
    "        shapes=[]\n",
    "        for i, data in enumerate(bboxes):    \n",
    "            bbox = data[0:4]\n",
    "            conf = round(data[4],2)\n",
    "            cls = result.names[data[5]]\n",
    "            dst_name = box2geotiff(bbox, img,dst_dir, image_name, ext, cls, i)\n",
    "\n",
    "            sam_gdf, shape_dict = box2sam(predictor, image, bbox, img_crs, conf, cls)\n",
    "            shapes.append(shape_dict)\n",
    "            if sam_gdf.crs != dst_crs:            \n",
    "                sam_gdf.to_crs(dst_crs, inplace=True)\n",
    "            geo_shape=pd.concat([sam_gdf, geo_shape])\n",
    "        \n",
    "        yolo_fdf = bboxes2df(xywh_bboxes, classes,confs, cols=['x','y','w','h'])\n",
    "        yolo_sdf=yolo_fdf[['Class','x','y','w','h']]#,'Conf']]\n",
    "        csv_name = f\"{dst_dir}/{image_name}.txt\"\n",
    "        yolo_sdf.to_csv(csv_name, header=False, sep=' ', index=False)        \n",
    "        yolo_gdf = bbox2points(yolo_fdf, image)#xywh_bboxes, image_name,width, height,image)        \n",
    "        if yolo_gdf.crs != dst_crs:            \n",
    "            yolo_gdf.to_crs(dst_crs, inplace=True)\n",
    "        geo_points=pd.concat([yolo_gdf, geo_points])\n",
    "    \n",
    "    label_dict = {\n",
    "      \"version\": \"5.2.1\",\n",
    "      \"flags\": {},\n",
    "      \"shapes\": shapes,\n",
    "      \"imagePath\": os.path.basename(image),\n",
    "      \"imageData\": None,\n",
    "      \"imageHeight\": height,\n",
    "      \"imageWidth\": width\n",
    "    }\n",
    "    \n",
    "    json_name = f\"{dst_dir}/{image_name}.json\"\n",
    "    out_file = open(json_name, 'w')\n",
    "    json.dump(label_dict,out_file,indent=2)\n",
    "    out_file.close()      \n",
    "        \n",
    "        \n",
    "geo_points.reset_index(drop=True)\n",
    "geo_points.crs=dst_crs\n",
    "point_gpkg = f\"{dst_dir}/point_detections.gpkg\"\n",
    "#geo_points.to_crs(dst_crs, inplace=True)\n",
    "geo_points.to_file(point_gpkg, layer='PointDetections', driver=\"GPKG\")\n",
    "\n",
    "\n",
    "geo_shape.reset_index(drop=True)\n",
    "geo_shape.crs=dst_crs\n",
    "shape_gpkg = f\"{dst_dir}/shape_detections.gpkg\"\n",
    "#geo_points.to_crs(dst_crs, inplace=True)\n",
    "geo_shape.to_file(shape_gpkg, layer='ShapesDetections', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e89f914b-c787-4b30-82a4-df6b0b6af88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image must by in EPSG:4326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a19caaea59e4212b86c3862e4f51d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_text…"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_select = PlotMap(geo_shape)\n",
    "map_select.add_gdf(geo_points,layer_name='PointsDetections')\n",
    "map_select"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
