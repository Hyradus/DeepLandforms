{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39659c2d-6b38-4491-a71b-c027be58d271",
   "metadata": {},
   "source": [
    "# **DeepLandforms - v2**\n",
    "\n",
    "Author: giacomo.nodjoumi@hyranet.info - g.nodjoumi@jacobs-university.de\n",
    "\n",
    "## DeepLandforms\n",
    "\n",
    "With this notebook, users can use train [YOLOv8](https://github.com/ultralytics/ultralytics) models for object detection and instance segmentation models on custom dataset of georeferenced images.\n",
    "Results can be visualized directly in the noteboo using leafmap and WMS backend.\n",
    "\n",
    "This notebook includes:\n",
    "* customizable augmentations using albumentation package\n",
    "* data train/valid split\n",
    "\n",
    "## Usage\n",
    "\n",
    "* Put or link the dataset into the **DeepLandforms** *.env* file\n",
    "* Run docker-compose up\n",
    "* Edit the *configs* section by editing the following parameters:\n",
    "\n",
    "## Parameters\n",
    " ------------------------------------------------------------------\n",
    "| **Parameter** | **Description** | **Example** |\n",
    "| ---- | ---- | ---- |\n",
    "| **data_dir** | local path of the data dir |  | /home/user/data |\n",
    "| **device** | device where to run the model | cuda or cpu |\n",
    "------------------------------------------------------------------\n",
    "Then just execute the notebook and monitor the training in **Tensorboard** container.\n",
    "\n",
    "## Funding\n",
    "*This study is within the Europlanet 2024 RI and EXPLORE project, and it has received funding from the European Unionâ€™s Horizon 2020 research and innovation programme under grant agreement No 871149 and No 101004214.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627bf8f-8d64-4bb3-9e20-5f6d209f5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2 as cv\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "from utils.DataUtils import get_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8eba5-9632-4a61-bf96-231869935879",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = 'BC_n_SQCRP_n_CellSize_10_m__LIM_n_None_px_cog_n_V2/YOLO/'\n",
    "home_dir = '/home/Giacomo/data/'\n",
    "src_path = f'{home_dir}/{basepath}'\n",
    "image_path = f'{home_dir}{basepath}'\n",
    "base_dir = src_path +'/train'\n",
    "#train_dir = f'{image_path}/train'\n",
    "if os.path.isdir(base_dir):\n",
    "    shutil.rmtree(base_dir)\n",
    "os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11372c-12a3-4e62-bc41-39c9c882b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f'{image_path}/train'\n",
    "if os.path.isdir(train_path):\n",
    "    shutil.rmtree(train_path)\n",
    "valid_path = f'{image_path}/val'\n",
    "if os.path.isdir(valid_path):\n",
    "    shutil.rmtree(valid_path)\n",
    "test_path = f'{image_path}/test'\n",
    "if os.path.isdir(test_path):\n",
    "    shutil.rmtree(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a29372-ec8f-4cc0-b2e3-52f5527ff8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [f\"{image_path}{image}\" for image in get_paths(image_path,'tiff')]\n",
    "label_list = [f\"{image_path}{label}\" for label in get_paths(image_path,'txt')]\n",
    "len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66816d42-8074-4cca-a357-59a87a965650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cls = []\n",
    "class_df = pd.DataFrame(columns=['Type','x0','y0','x1','y1'])\n",
    "for ll in label_list:\n",
    "    df = pd.read_csv(ll, delimiter=' ', header=None)\n",
    "    df.columns=['Type','x0','y0','x1','y1']\n",
    "    class_df=pd.concat([df,class_df]).reset_index(drop=True)\n",
    "    cls.append(df.iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0112aa-1856-4b81-b67f-d506636a50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45bcdc1-2095-4b52-ae82-65e7574f64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28001143-7940-4498-962a-1dd180ce88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image, reshape_as_raster\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "def augment_data(image_file, label_file, img, version, augmentations_list):\n",
    "    \n",
    "    image = reshape_as_image(img.read())\n",
    "    with open(label_file, 'r') as f:\n",
    "        annotations = f.readlines()\n",
    "    \n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        for annotation in annotations:\n",
    "            label, *bbox = map(float, annotation.strip().split())\n",
    "            bboxes.append(bbox)\n",
    "            labels.append(label)\n",
    "            \n",
    "    #print(augmentations)\n",
    "    for k in augmentation_dict:\n",
    "        aug = augmentation_dict[k]\n",
    "        augmentation = A.Compose([aug], bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids']))\n",
    "    \n",
    "    \n",
    "       \n",
    "    \n",
    "        augmented = augmentation(image=image, bboxes=bboxes, category_ids=labels)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_bboxes = np.array(augmented['bboxes'])\n",
    "        augmented_labels = np.array(augmented['category_ids'])\n",
    "    \n",
    "        basename, ext = os.path.splitext(image_file)\n",
    "        savename = f\"{basename}_augmented_{version}_{k}{ext}\"\n",
    "        with rio.open(savename, 'w', **img.meta) as dst:\n",
    "            dst.write(reshape_as_raster(augmented_image))\n",
    "    \n",
    "        with open(f\"{basename}_augmented_{version}_{k}.txt\", 'w') as f:\n",
    "            for label, bbox in zip(augmented_labels, augmented_bboxes):\n",
    "                x_center = bbox[0]# / augmented_image.shape[1]\n",
    "                y_center = bbox[1]# / augmented_image.shape[0]\n",
    "                width = bbox[2] #/ augmented_image.shape[1]\n",
    "                height = bbox[3]# / augmented_image.shape[0]\n",
    "                f.write(f\"{int(label)} {x_center} {y_center} {width} {height}\\n\")\n",
    "    \n",
    "        #print(\"Augmentation complete.\")\n",
    "    return augmented_image, augmented_bboxes, augmented_labels, savename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02962ca3-6569-4f36-82b3-8e0f2d3854fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def parallel_augss(image_files, label_files, augmentations, resize, version, JOBS):\n",
    "    from joblib import Parallel, delayed, parallel_backend\n",
    "    with parallel_backend(\"loky\", inner_max_num_threads=2):\n",
    "    \n",
    "        results = Parallel (n_jobs=JOBS)(delayed(data_augmenter)(image_files[i], label_files[i], version, augmentations, resize)\n",
    "                            for i in range(len(image_files)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a38ec8-da6d-43ab-8420-3f217f330964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmenter(image_file, label_file, version, augmentations, resize):\n",
    "    image_file=image_file        \n",
    "    label_file =label_file        \n",
    "    img = rio.open(image_file)\n",
    "    rnd=np.random.randint(1.5,3)\n",
    "    if resize==True:            \n",
    "        augmentations['resize']=A.RandomSizedBBoxSafeCrop(height=math.ceil(img.height / rnd), width=math.ceil(img.width / rnd), erosion_rate=0.0, interpolation=1, always_apply=False)#, p=.25)        \n",
    "    return(augment_data(image_file, label_file, img, version=version, augmentations_list=augmentations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09c0e9-2ceb-4937-bfe8-a5fbf9061437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_creator(item_list, chunksize):\n",
    "    import itertools\n",
    "    it = iter(item_list)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, chunksize))\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe3694-d21b-48f6-a1b9-94be5b82585b",
   "metadata": {},
   "source": [
    "# Initialize augmentation sets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d507aa6-81a1-49d0-8af7-799f2e50c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104e839-450e-4226-9fc6-3d0c7bdff43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.uniform(1,3)\n",
    "resize:True\n",
    "version=1\n",
    "augmentation_dict = {\n",
    "    \"clahe\":A.CLAHE(),#p=.25),\n",
    "    #\"rotate\":A.RandomRotate90(),#p=.5),\n",
    "    #\"transpose\":A.Transpose(),#p=.25),\n",
    "    \"shiftscale\":A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.30, rotate_limit=25,always_apply=True),#, p=.25),\n",
    "    \"rbc\":A.RandomBrightnessContrast(always_apply=True),#p=0.5),\n",
    "    \"blur\":A.Blur(blur_limit=4),#, p=.25),\n",
    "    \"optdis\":A.OpticalDistortion(distort_limit=0.5, shift_limit=0.35, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=True),\n",
    "    \"GauNoise\":A.GaussNoise(var_limit=(30.0, 60.0), mean=0,always_apply=True),    \n",
    "    \"MNoise\":A.MultiplicativeNoise(multiplier=(0.5, 1.5), per_channel=False, elementwise=True,always_apply=True),\n",
    "    #\"Fog\":A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.9, alpha_coef=0.1,always_apply=True),\n",
    "    \"Sharp\":A.Sharpen(alpha=(0.6, 0.9), lightness=(0.5, 1.0),always_apply=True),    \n",
    "                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e2458-3e6d-4de7-b2b0-617ceeb64038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in augmentation_dict:\n",
    "    print(augmentation_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23ab10-1156-468f-abaf-88b3f1d66a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "from tqdm import tqdm\n",
    "avram=psutil.virtual_memory().total >> 30\n",
    "avcores=psutil.cpu_count(logical=False)\n",
    "JOBS = avcores\n",
    "#for aug_set in augmentations_list:\n",
    "    #version = aug_set[2]\n",
    "    #resize =aug_set[1]\n",
    "    #augmentations= aug_set[0]\n",
    "with tqdm(total=len(image_list),\n",
    "         desc = 'Generating Images',\n",
    "         unit='File') as pbar:\n",
    "    \n",
    "    filerange = len(image_list)\n",
    "    chunksize = round(filerange/JOBS)\n",
    "    if chunksize <1:\n",
    "        chunksize=1\n",
    "        JOBS = filerange\n",
    "    image_chunks = []\n",
    "    for c in chunk_creator(image_list, JOBS):\n",
    "        image_chunks.append(c)\n",
    "    label_chunks = []\n",
    "    for c in chunk_creator(label_list, JOBS):\n",
    "        label_chunks.append(c)\n",
    "    for i in range(len(image_chunks)):\n",
    "        image_files = image_chunks[i]\n",
    "        label_files = label_chunks[i]        \n",
    "        try:\n",
    "            results=parallel_augss(image_files, label_files, augmentation_dict,  True, 1, JOBS)                               \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(image_files)\n",
    "        \n",
    "        pbar.update(len(image_files))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683e51f-33a9-40dc-9cfb-e759d05b58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [f\"{image_path}{image}\" for image in get_paths(image_path,'tiff')]\n",
    "label_list = [f\"{image_path}{label}\" for label in get_paths(image_path,'txt')]\n",
    "len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506f396-69a5-4c2a-90b1-a3a41144d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc=0.7\n",
    "valid_perc=0.2\n",
    "test_perc=0.1\n",
    "train_set, valid_set = train_test_split(image_list, test_size=test_perc+valid_perc, random_state=1,shuffle=False)\n",
    "valid_set, test_set = train_test_split(valid_set, test_size=valid_perc, random_state=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab476631-5169-4ded-9d9b-69e90cab65e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ca8ae-e4ec-4948-b47d-e2aec3227ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc0d44-113d-4186-a104-e34ffd6b4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43799cb-2531-4047-af9b-de92314c2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataMoverYOLO(dst_root, image_list):\n",
    "    try:\n",
    "        os.makedirs(dst_root)\n",
    "    except:\n",
    "        shutil.rmtree(dst_root)\n",
    "        os.makedirs(dst_root)\n",
    "    images_path = f\"{dst_root}/images\"\n",
    "    os.makedirs(images_path)\n",
    "    labels_path = f\"{dst_root}/labels\"        \n",
    "    os.makedirs(labels_path)\n",
    "    for i, image in enumerate(image_list):  \n",
    "        pathname, ext =os.path.splitext(image)\n",
    "        label= f\"{pathname}.txt\"\n",
    "        name = f\"{os.path.basename(pathname)}\"        \n",
    "        shutil.copy(image, f\"{images_path}/{name}{ext}\")\n",
    "        shutil.copy(label, f\"{labels_path}/{name}.txt\")\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d0bcb-66a8-4562-9ab9-6b311a7680da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMoverYOLO(train_path, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077cacc3-01bc-4e63-b106-a87aa632cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMoverYOLO(test_path, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98065021-65b8-4a67-a194-2d448c1f4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMoverYOLO(valid_path, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf6a92-233d-424b-a912-1b1a32a422f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = f\"{src_path}classes.csv\"\n",
    "class_df = pd.read_csv(class_file, header=None, delimiter=' ')\n",
    "class_df.columns=['Type']\n",
    "classnum=len(class_df)\n",
    "class_names=class_df.Type.to_list()#['0', '1','2', '3', '4']\n",
    "yaml_file = f\"{src_path}/data.yaml\"\n",
    "lines = [f\"train: train/images\\nval: val/images\\nnc: {classnum}\\nnames: {class_names}\"]\n",
    "with open(yaml_file, 'w') as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bdd5a3-7674-43f6-b06e-f19d4a8dedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8x.pt')\n",
    "results = model.train(\n",
    "   data=yaml_file,\n",
    "   imgsz=640,\n",
    "   epochs=150,\n",
    "   batch=4,\n",
    "   val=True,\n",
    "   name='yolov8x_custom_640_multiclass_10m_Augm',\n",
    "    seed=0,\n",
    "deterministic=True,\n",
    "cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f66b7-7981-467d-a1bd-00264b6de5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.export_visuals(export_dir=\"demo_data/\")\n",
    "\n",
    "Image(\"demo_data/prediction_visual.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
