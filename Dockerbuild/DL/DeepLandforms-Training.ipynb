{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DeepLandforms**\n",
    "\n",
    "Author: giacomo.nodjoumi@hyranet.info - g.nodjoumi@jacobs-university.de\n",
    "\n",
    "## DeepLandforms Training\n",
    "\n",
    "With this notebook, users can train instance segmentation models on custom dataset of georeferenced images.\n",
    "The models are based on state-of-the-art general purpose architectures, available [here](https://github.com/facebookresearch/detectron2).\n",
    "Despite several types of networks are supported, such as object detection, image segmentation ad instance segmentation, and available in the above repository, this notebook and the complementary **DeepLandrorms-Segmentation** notebook are specific for instance segmentation architectures for georefernced images.\n",
    "\n",
    "## Usage\n",
    "\n",
    "* Prepare the dataset in COCO label format, using provided **LabelMe** container or else.\n",
    "* Put or link the dataset into the **DeepLandforms** *.env* file\n",
    "* Run docker-compose up\n",
    "* Edit the *configs* section by editing the following parameters:\n",
    "------------------------------------------------------------------\n",
    "| **Parameter** | **Function** | **Common Values** |\n",
    "| ---- | ---- | ---- |\n",
    "| **cfg.merge_from_file(model_zoo.get_config_file(\"\"))** | Model Architecture | MASK-R-CNN in this work |\n",
    "| **cfg.TEST.EVAL_PERIOD** |  N° of epochs after an evaluation is performed | depending on SOLVER.MAX_ITER, usually every 1/10 of ITER, e.g. every 1000 on a 10000 iter |\n",
    "| **cfg.DATALOADER.NUM_WORKERS** | Number of workers for dataloader | usually correspond to cpu cores |\n",
    "| **cfg.MODEL.WEIGHTS** | model_zoo.get_checkpoint_url(\"\") | Optional but advised to start from a pretrained model from the model zoo, MUST be of the same architecture of the get_config_file. see default values as example. |\n",
    "| **cfg.SOLVER.IMS_PER_BATCH** | How many image to be ingested, depends on the performance of the GPU, especiall VRAM |  up to 8 for 8GB VRAM |\n",
    "| **cfg.SOLVER.BASE_LR** | learning rate | 0.0002 is a good starting point |\n",
    "| **cfg.SOLVER.MAX_ITER** | N° of epochs | Rise up for low mAP, lower to prevent overfitting |\n",
    "| **cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE** | parameter to sample a subset of proposals coming out of RPN to calculate cls and reg loss during training. | multiple of 2, commonly 64 |\n",
    "------------------------------------------------------------------\n",
    "Then just execute the notebook and monitor the training in **Tensorboard** container.\n",
    "\n",
    "## Funding\n",
    "*This study is within the Europlanet 2024 RI and EXPLORE project, and it has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 871149 and No 101004214.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from utils.detectron_utils import Trainer\n",
    "from utils.train_utils import categories_gen, classes_distribution, dataframes_gen, dataMover, getmeta, classDump, label2coco, dsReg, trainaugmenter\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import labelme2coco\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog\n",
    "from colour import Color\n",
    "import json\n",
    "from detectron2.data.catalog import Metadata\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.GenUtils import get_paths, folder_file_size, chunk_creator\n",
    "import rasterio as rio\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = 'MARSPIT_v2/MixRes/filtered_in/'\n",
    "home_dir = '/home/user/data/'\n",
    "src_path = f'{home_dir}/{basepath}'\n",
    "image_path = f'{home_dir}{basepath}'\n",
    "base_dir = src_path +'/train'\n",
    "#train_dir = f'{image_path}/train'\n",
    "if os.path.isdir(base_dir):\n",
    "    shutil.rmtree(base_dir)\n",
    "os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f'{image_path}/train_data'\n",
    "if os.path.isdir(train_path):\n",
    "    shutil.rmtree(train_path)\n",
    "valid_path = f'{image_path}/valid_data'\n",
    "if os.path.isdir(valid_path):\n",
    "    shutil.rmtree(valid_path)\n",
    "test_path = f'{image_path}/test_data'\n",
    "if os.path.isdir(test_path):\n",
    "    shutil.rmtree(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'dataset.json'\n",
    "dataset_path = f'{src_path}/{dataset_name}'\n",
    "dataset_path\n",
    "if exists(dataset_path):\n",
    "    os.remove(dataset_path)\n",
    "    \n",
    "dataset, dataset_meta, dataset_classes = dsReg(f'{src_path}', dataset_name, base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_dis, valid_df_dis, test_df_dis, train, valid, test = dataframes_gen(dataset_classes, dataset, 0.6,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMover(image_path, train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainaugmenter(f'{image_path}/train_data',f'{image_path}/train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = 'dataset.json'\n",
    "train_path = f'{image_path}/train_data'\n",
    "train_json = f'{train_path}/{train_name}'\n",
    "if exists(train_json):\n",
    "    os.remove(train_json)\n",
    "train, train_meta, train_classes = dsReg(train_path, 'traindata', train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_name = 'dataset.json'\n",
    "valid_path = f'{image_path}/valid_data'\n",
    "valid_json = f'{valid_path}/{valid_name}'\n",
    "if exists(valid_json):\n",
    "    os.remove(valid_json)\n",
    "valid, valid_meta, valid_classes = dsReg(valid_path, 'valid_data', valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = 'dataset.json'\n",
    "test_path = f'{image_path}/test_data'\n",
    "test_json = f'{test_path}/{test_name}'\n",
    "if exists(test_json):\n",
    "    os.remove(test_json)\n",
    "test, test_meta, test_classes = dsReg(test_path, 'test_data', test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def clsdis(categories, datatype, classes):    \n",
    "    classes_dis=[]\n",
    "    for cat in categories:\n",
    "    #    print(classes[cat])\n",
    "        classes_dis.append(classes[cat])\n",
    "    classes_dis =list(zip(classes_dis,[datatype for i in range(len(classes_dis))]))\n",
    "    df_dis = pd.DataFrame(classes_dis, columns=['Class','Dataset'])\n",
    "    return df_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = categories_gen(train)\n",
    "train_df_dis = clsdis(train_cat, 'Train', train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset_classes\n",
    "plt.figure(figsize = (10,5), facecolor='white',dpi=300)\n",
    "plt.suptitle('Class-labels distributions', fontsize=15)\n",
    "ax1 = plt.subplot(131)\n",
    "train_df_dis.groupby(['Class']).count().plot(kind='pie', figsize=(10,1,0), autopct=lambda p:f'{p:.2f}%, \\n{p*len(train_df_dis)/100:.0f} labels',startangle=90, subplots=True, ax =ax1, fontsize=5, legend=False)\n",
    "plt.title('Train Dataset\\n{} Labels'.format(len(train_df_dis), loc='center'))\n",
    "ax2 = plt.subplot(132)\n",
    "valid_df_dis.groupby(['Class']).count().plot(kind='pie', figsize=(10,10),autopct=lambda p:f'{p:.2f}%, \\n{p*len(valid_df_dis)/100:.0f} labels',startangle=90, subplots=True, ax =ax2, fontsize=5,legend=False)\n",
    "plt.title('Valid Dataset\\n{} Labels'.format(len(valid_df_dis), loc='center', ))\n",
    "ax3 = plt.subplot(133)\n",
    "test_df_dis.groupby(['Class']).count().plot(kind='pie', figsize=(10,10),autopct=lambda p:f'{p:.2f}%, \\n{p*len(test_df_dis)/100:.0f} labels',startangle=90, subplots=True, ax =ax3, fontsize=5,legend=False)\n",
    "plt.title('Test Dataset\\n{} Labels'.format(len(test_df_dis), loc='center', ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONFIGS - edit befor run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "#model_config='mask_rcnn_R_50_C4_1x.yaml'\n",
    "model_config='mask_rcnn_R_50_FPN_1x.yaml'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/\"+model_config))\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = ('traindata',)\n",
    "cfg.DATASETS.TEST = ('valid_data',)\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/\"+model_config)  # Let training initialize from model zoo\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "#cfg.MODEL.MASK_ON = True\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "#cfg.SOLVER.BASE_LR = 0.001\n",
    "#cfg.SOLVER.BASE_LR = 0.00025\n",
    "#cfg.SOLVER.BASE_LR = 0.00015\n",
    "#cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "#cfg.SOLVER.MAX_ITER = 10000 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD= 5000\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 10000  # and a good number of iterations\n",
    "cfg.SOLVER.STEPS = (6000, 7000, 8000,9000) \n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Solver\n",
    "#cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "#cfg.SOLVER.BASE_LR = 0.001\n",
    "#cfg.SOLVER.BASE_LR = 0.00025\n",
    "#cfg.SOLVER.BASE_LR = 0.0001\n",
    "#cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "#cfg.SOLVER.MAX_ITER = 15000 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "#cfg.SOLVER.CHECKPOINT_PERIOD= 2500\n",
    "#cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "#cfg.SOLVER.STEPS = (200,400,600, 800)\n",
    "#cfg.SOLVER.GAMMA = 0.05\n",
    "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE =  1024\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(train_classes)  \n",
    "cfg.OUTPUT_DIR = base_dir\n",
    "#cfg.INPUT.MIN_SIZE_TRAIN = 640\n",
    "#cfg.INPUT.MAX_SIZE_TRAIN = 900\n",
    "#cfg.INPUT.MIN_SIZE_TEST = 640\n",
    "#cfg.INPUT.MAX_SIZE_TEST = 900\n",
    "cfg.SOLVER.AMP.ENABLED=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in random.sample(train, 1):\n",
    "    #srpath = f'{image_path}/train_data/'\n",
    "    img_path = d[\"file_name\"]\n",
    "    print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    visualizer = Visualizer(img[:, :, 1:-1], metadata=train_meta, scale=2)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.imshow(out.get_image()[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "experiment_folder = '../data/MARSPIT_v2/MixRes/filtered_in/train'\n",
    "\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = []\n",
    "train_iter = []\n",
    "for x in experiment_metrics:\n",
    "    try:\n",
    "        train_val.append(x['total_loss'])\n",
    "        train_iter.append(x['iteration'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(\n",
    "    train_iter,\n",
    "    train_val)\n",
    "plt.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
    "    [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x])\n",
    "plt.legend(['total_loss', 'validation_loss'], loc='upper left', fontsize=15)\n",
    "plt.xlabel('Epochs', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.title('Total/Validation Loss', fontsize=15)\n",
    "\n",
    "plt.savefig('../data/MARSPIT_v2/MixRes/filtered_in/train/total_val_loss.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
