{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DeepLandforms**\n",
    "\n",
    "Author: giacomo.nodjoumi@hyranet.info - g.nodjoumi@jacobs-university.de\n",
    "\n",
    "## DeepLandforms Training\n",
    "\n",
    "With this notebook, users can train instance segmentation models on custom dataset of georeferenced images.\n",
    "The models are based on state-of-the-art general purpose architectures, available [here](https://github.com/facebookresearch/detectron2).\n",
    "Despite several types of networks are supported, such as object detection, image segmentation ad instance segmentation, and available in the above repository, this notebook and the complementary **DeepLandrorms-Segmentation** notebook are specific for instance segmentation architectures for georefernced images.\n",
    "\n",
    "## Usage\n",
    "\n",
    "* Prepare the dataset in COCO label format, using provided **LabelMe** container or else.\n",
    "* Put or link the dataset into the **DeepLandforms** *.env* file\n",
    "* Run docker-compose up\n",
    "* Edit the *configs* section by editing the following parameters:\n",
    "------------------------------------------------------------------\n",
    "| **Parameter** | **Function** | **Common Values** |\n",
    "| ---- | ---- | ---- |\n",
    "| **cfg.merge_from_file(model_zoo.get_config_file(\"\"))** | Model Architecture | MASK-R-CNN in this work |\n",
    "| **cfg.TEST.EVAL_PERIOD** |  N° of epochs after an evaluation is performed | depending on SOLVER.MAX_ITER, usually every 1/10 of ITER, e.g. every 1000 on a 10000 iter |\n",
    "| **cfg.DATALOADER.NUM_WORKERS** | Number of workers for dataloader | usually correspond to cpu cores |\n",
    "| **cfg.MODEL.WEIGHTS** | model_zoo.get_checkpoint_url(\"\") | Optional but advised to start from a pretrained model from the model zoo, MUST be of the same architecture of the get_config_file. see default values as example. |\n",
    "| **cfg.SOLVER.IMS_PER_BATCH** | How many image to be ingested, depends on the performance of the GPU, especiall VRAM |  up to 8 for 8GB VRAM |\n",
    "| **cfg.SOLVER.BASE_LR** | learning rate | 0.0002 is a good starting point |\n",
    "| **cfg.SOLVER.MAX_ITER** | N° of epochs | Rise up for low mAP, lower to prevent overfitting |\n",
    "| **cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE** | parameter to sample a subset of proposals coming out of RPN to calculate cls and reg loss during training. | multiple of 2, commonly 64 |\n",
    "------------------------------------------------------------------\n",
    "Then just execute the notebook and monitor the training in **Tensorboard** container.\n",
    "\n",
    "## Funding\n",
    "*This study is within the Europlanet 2024 RI and EXPLORE project, and it has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 871149 and No 101004214.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from utils.detectron_utils import Trainer\n",
    "from utils.train_utils import categories_gen, classes_distribution, dataframes_gen, dataMover, datasetReg\n",
    "from detectron2.evaluation import COCOEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, meta, classes , train_dir, image_path = datasetReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_dis, valid_df_dis, test_df_dis, train, valid, test = dataframes_gen(classes, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONFIGS - edit befor run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "model_config='mask_rcnn_R_50_FPN_3x.yaml'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/\"+model_config))\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = ('train_data',)\n",
    "cfg.DATASETS.TEST = ('valid_data',)\n",
    "cfg.TEST.EVAL_PERIOD = 250\n",
    "cfg.DATALOADER.NUM_WORKERS = 6\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/\"+model_config)  # Let training initialize from model zoo\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 24\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "#cfg.SOLVER.STEPS=(1000,)\n",
    "cfg.SOLVER.MAX_ITER = 5000 \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE =  128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)  \n",
    "cfg.OUTPUT_DIR = train_dir\n",
    "cfg.INPUT.MIN_SIZE_TEST = 500\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1000\n",
    "cfg.SOLVER.AMP.ENABLED=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMover(image_path, train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = classes\n",
    "plt.figure(figsize = (10,5), facecolor='white',dpi=300)\n",
    "plt.suptitle('Class-labels distributions', fontsize=15)\n",
    "ax1 = plt.subplot(131)\n",
    "train_df_dis.groupby(['Class']).count().plot(kind='pie', figsize=(10,1,0), autopct=lambda p:f'{p:.2f}%, \\n{p*len(train_df_dis)/100:.0f} labels',startangle=90, subplots=True, ax =ax1, fontsize=5, legend=False)\n",
    "plt.title('Train Dataset\\n{} Labels'.format(len(train_df_dis), loc='center'))\n",
    "ax2 = plt.subplot(132)\n",
    "valid_df_dis.groupby(['Class']).count().plot(kind='pie', figsize=(10,10),autopct=lambda p:f'{p:.2f}%, \\n{p*len(valid_df_dis)/100:.0f} labels',startangle=90, subplots=True, ax =ax2, fontsize=5,legend=False)\n",
    "plt.title('Valid Dataset\\n{} Labels'.format(len(valid_df_dis), loc='center', ))\n",
    "ax3 = plt.subplot(133)\n",
    "test_df_dis.groupby(['Class']).count().plot(kind='pie', figsize=(10,10),autopct=lambda p:f'{p:.2f}%, \\n{p*len(test_df_dis)/100:.0f} labels',startangle=90, subplots=True, ax =ax3, fontsize=5,legend=False)\n",
    "plt.title('Test Dataset\\n{} Labels'.format(len(test_df_dis), loc='center', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in random.sample(train, 1):\n",
    "    img_path = d[\"file_name\"]\n",
    "    print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    visualizer = Visualizer(img[:, :, 1:-1], metadata=meta, scale=2)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.imshow(out.get_image()[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
