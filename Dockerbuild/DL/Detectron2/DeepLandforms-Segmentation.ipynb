{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DeepLandforms**\n",
    "\n",
    "Author: giacomo.nodjoumi@hyranet.info - g.nodjoumi@jacobs-university.de\n",
    "\n",
    "## DeepLandforms Segmentation\n",
    "\n",
    "With this notebook, users can use custom trained models for instance segmentation models on custom dataset of georeferenced images.\n",
    "The output consist of a folder containing:\n",
    "* Source Images in which at least one detection occurred\n",
    "* Label file in COCO json format for each image\n",
    "* Geopackage containing a single layer with image name, confidence leve, class.\n",
    "\n",
    "## Usage\n",
    "\n",
    "* Put or link the dataset into the **DeepLandforms** *.env* file\n",
    "* Run docker-compose up\n",
    "* Edit the *configs* section by editing the following parameters:\n",
    "------------------------------------------------------------------\n",
    "| **Parameter** | **Function** | **Common Values** |\n",
    "| ---- | ---- | ---- |\n",
    "| **batch_size** | N° of images to be processed at once | Depending on VRAM and image size, up to 8 per 8GB VRAM |\n",
    "| **geopackage_name** |  Name of the final geopackage |  |\n",
    "| **proj_geopackage_name** | Name of the final geopackage in custom projection | |\n",
    "| **model_path** | local path and name of the model  | it should start with /pre-trained_models/ |\n",
    "| **model_yaml** | Model Architecture | MASK-R-CNN in this work | EDIT according to trained model selected |\n",
    "| **dst_crs** | CRS of the geopackage | provide as WKT or proj4 |\n",
    "\n",
    "------------------------------------------------------------------\n",
    "Then just execute the notebook and monitor the training in **Tensorboard** container.\n",
    "\n",
    "## Funding\n",
    "*This study is within the Europlanet 2024 RI and EXPLORE project, and it has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 871149 and No 101004214.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from datetime import datetime\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.catalog import Metadata\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from pyproj import CRS\n",
    "#from pycocotools import mask\n",
    "import random\n",
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import shutil\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.GenUtils import get_paths\n",
    "from utils.detectron_utils import CustomPredictor\n",
    "from utils.geoshape_utils import parallel_funcs, chunk_creator, mask2shape, pred2coco, pred2shape, crs_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 with Max-Q Design'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION - edit befor run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "image_path = '../data/BC_n_SQCRP_n_CellSize_10_m__LIM_n_None_px_cog_n/test_data'\n",
    "geopackage_name = '/Inferred_Shapes.gpkg' ## Example for HiRISE \n",
    "proj_geopackage_name = '/Inferred_Shapes_projected.gpkg' ## Example for HiRISE \n",
    "model_path = '/home/user/data/TrainedModels/5m_re-ok-2/model_final.pth'\n",
    "model_yaml = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\" ## EDIT according to trained model selected\n",
    "#src_crs = CRS.from_user_input('PROJCRS[\"Equirectangular MARS\", BASEGEOGCRS[\"GCS_MARS\",DATUM[\"unnamed\",ELLIPSOID[\"unnamed\",3393833.2607584,0,LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]],PRIMEM[\"Reference meridian\",0,ANGLEUNIT[\"degree\",0.0174532925199433,ID[\"EPSG\",9122]]]],CONVERSION[\"unnamed\",METHOD[\"Equidistant Cylindrical\",ID[\"EPSG\",1028]],PARAMETER[\"Latitude of natural origin\",20,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",180,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Latitude of 1st standard parallel\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8823]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"northing\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]')\n",
    "#dst_crs = CRS.from_user_input('PROJCS[\"Equirectangular MARS\",GEOGCS[\"GCS_MARS\",DATUM[\"unnamed\",SPHEROID[\"unnamed\",3395582.0270805,0]],PRIMEM[\"Reference meridian\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Equirectangular\"],PARAMETER[\"latitude_of_origin\",10],PARAMETER[\"central_meridian\",180],PARAMETER[\"standard_parallel_1\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]')\n",
    "#dst_crs = CRS.from_wkt('PROJCRS[\"Equirectangular MARS\", BASEGEOGCRS[\"GCS_MARS\", DATUM[\"unnamed\", ELLIPSOID[\"unnamed\",3396190,0, LENGTHUNIT[\"metre\",1,  ID[\"EPSG\",9001]]]], PRIMEM[\"Reference meridian\",0, ANGLEUNIT[\"degree\",0.0174532925199433,\t\tID[\"EPSG\",9122]]]], CONVERSION[\"Equidistant Cylindrical\", METHOD[\"Equidistant Cylindrical\", ID[\"EPSG\",1028]], PARAMETER[\"Latitude of 1st standard parallel\",0, ANGLEUNIT[\"degree\",0.0174532925199433], ID[\"EPSG\",8823]], PARAMETER[\"Longitude of natural origin\",180, ANGLEUNIT[\"degree\",0.0174532925199433], ID[\"EPSG\",8802]], PARAMETER[\"False easting\",0, LENGTHUNIT[\"metre\",1], ID[\"EPSG\",8806]], PARAMETER[\"False northing\",0, LENGTHUNIT[\"metre\",1], ID[\"EPSG\",8807]]], CS[Cartesian,2], AXIS[\"easting\",east, ORDER[1], LENGTHUNIT[\"metre\",1, ID[\"EPSG\",9001]]], AXIS[\"northing\",north, ORDER[2], LENGTHUNIT[\"metre\",1, ID[\"EPSG\",9001]]]]')\n",
    "dst_crs_2 = CRS.from_user_input('GEOGCRS[\"GCS_Mars_2000_Sphere\", DATUM[\"Mars_2000_(Sphere)\", ELLIPSOID[\"Mars_2000_Sphere_IAU_IAG\",3396190,0, LENGTHUNIT[\"metre\",1]], ID[\"ESRI\",106971]], PRIMEM[\"Reference_Meridian\",0, ANGLEUNIT[\"Degree\",0.0174532925199433]], CS[ellipsoidal,2], AXIS[\"longitude\",east, ORDER[1], ANGLEUNIT[\"Degree\",0.0174532925199433]], AXIS[\"latitude\",north, ORDER[2], ANGLEUNIT[\"Degree\",0.0174532925199433]]]')\n",
    "#dst_crs = CRS.from_wkt('GEOGCS[\"Moon 2000\",DATUM[\"D_Moon_2000\",SPHEROID[\"Moon_2000_IAU_IAG\",1737400.0,0.0]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(thing_classes=['Type-4', 'Crater', 'Type-3', 'Type-1', 'Type-2'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = image_path+'/outputs'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "class_file = os.path.dirname(model_path)+'/trained_classes.csv'\n",
    "class_df = pd.read_csv(class_file)\n",
    "classes = class_df[class_df.columns[0]].tolist()\n",
    "meta = Metadata()\n",
    "meta.set(thing_classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_paths(image_path,'tiff')\n",
    "src_crs = CRS.from_wkt(rio.open(image_path+'/'+images[0]).crs.to_wkt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model_yaml))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =  len(classes)\n",
    "cfg.MODEL.WEIGHTS = model_path\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "#cfg.INPUT.MIN_SIZE_TEST = 32\n",
    "#cfg.INPUT.MAX_SIZE_TEST = 32\n",
    "#cfg.INPUT.MIN_SIZE_TRAIN =32\n",
    "#cfg.INPUT.MAX_SIZE_TRAIN = 32\n",
    "cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE =  10000\n",
    "cfg.SOLVER.AMP.ENABLED=True\n",
    "#cfg.MODEL.RPN.IN_FEATURES = ['p2', 'p3', 'p4', 'p5', 'p6']\n",
    "#cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0, 4.0, 8.0]]\n",
    "#cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[4], [8], [16], [64], [128]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../data/BC_n_SQCRP_n_CellSize_10_m__LIM_n_None_px_cog_n/test_data/outputs/Processed.csv'\n"
     ]
    }
   ],
   "source": [
    "cols = ['Name','Class','Score']\n",
    "dst_gpkg = out_dir+'/Inferred_Shapes_projected.gpkg'\n",
    "proc_csv = out_dir+'/Processed.csv'\n",
    "#try:\n",
    "#    geoshapes = gpd.read_file(dst_gpkg)\n",
    "#except Exception as e:\n",
    "#    print(e)\n",
    "#    geoshapes = None\n",
    "    #geoshapes = gpd.GeoDataFrame(columns=cols)\n",
    "#    pass\n",
    "try:\n",
    "    proc_df = pd.read_csv(proc_csv)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    proc_df = pd.DataFrame(columns=['Name','Detections'])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = list(chunk_creator(images,batch_size))\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geopackager(gdf,i,geoshapes):\n",
    "    try:\n",
    "        geoshapes.crs\n",
    "    except:\n",
    "        geoshapes = gdf\n",
    "    init_crs = geoshapes.crs\n",
    "    try:\n",
    "        if gdf.crs != init_crs:\n",
    "            gdf = gdf.to_crs(init_crs)\n",
    "        #geoshapes = gpd.GeoDataFrame(pd.concat([geoshapes,gdf],ignore_index=True),crs=init_crs)\n",
    "    except Exception as e:\n",
    "        #geoshapes = gdf\n",
    "        #geoshapes = gpd.GeoDataFrame(pd.concat([geoshapes,gdf],ignore_index=True),crs=init_crs)\n",
    "        print(e)            \n",
    "        pass\n",
    "    geoshapes = gpd.GeoDataFrame(pd.concat([geoshapes,gdf]).drop_duplicates().reset_index(drop=True),crs=init_crs)\n",
    "    geoshapes = geoshapes[np.isnan(geoshapes['geometry'].area) == False]\n",
    "    geoshapes.to_file(out_dir+proj_geopackage_name, driver='GPKG', crs=init_crs) \n",
    "    return geoshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #### To be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images:   0%|          | 0/19 [00:00<?, ?File/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'windowed_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m open_images \u001b[38;5;241m=\u001b[39m [rio\u001b[38;5;241m.\u001b[39mopen(img_path) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#imgs = [reshape_as_image(image.read()) for image in open_images]\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m imgs, windows_dict \u001b[38;5;241m=\u001b[39m \u001b[43mwindowed_imgs\u001b[49m(open_images[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m250\u001b[39m, paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(imgs)):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#print(windows_dict['Transforms'][i])\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m CP(imgs[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'windowed_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "#CP = CustomPredictor(cfg)\n",
    "from detectron2.engine import DefaultPredictor\n",
    "CP = DefaultPredictor(cfg)\n",
    "JOBS=psutil.cpu_count(logical=False)\n",
    "with tqdm(total=len(images),\n",
    "             desc = 'Generating Images',\n",
    "             unit='File') as pbar:\n",
    "    start = datetime.now()\n",
    "    gdf_list = []\n",
    "    for d in range(len(chunks)):\n",
    "    #for d in range(1):\n",
    "        chunk = list(chunks[d])\n",
    "\n",
    "        lambda_f = lambda element:element not in proc_df['Name'].to_list()\n",
    "        #lambda_f = lambda element:element not in geoshapes['Name'].to_list()\n",
    "        filtered = filter(lambda_f, chunk)\n",
    "\n",
    "        chunk = list(filtered)\n",
    "        if len(chunk)>0:\n",
    "            paths = [image_path+'/'+ele for ele in chunk]\n",
    "            open_images = [rio.open(img_path) for img_path in paths]\n",
    "            #imgs = [reshape_as_image(image.read()) for image in open_images]\n",
    "            imgs, windows_dict = windowed_imgs(open_images[0], 0, 250, paths[0])\n",
    "            for i in range(len(imgs)):\n",
    "                #print(windows_dict['Transforms'][i])\n",
    "                               \n",
    "                predictions = CP(imgs[i])\n",
    "                masks = predictions['instances'].pred_masks.cpu().numpy()           \n",
    "                if len(masks)>0:                \n",
    "                    for l in range(len(predictions)):\n",
    "                        print(l)\n",
    "                        #gdf = pred2shape(predictions, windows_dict['Names'][i], open_images[i],classes, JOBS, out_dir, i)    \n",
    "                        gdf = pred2shape(predictions, l,windows_dict['Names'][i], windows_dict['Transforms'][i], open_images[0].crs ,classes, JOBS, out_dir, i)    \n",
    "                        gdf_list.append(gdf)\n",
    "                        tmp_df = pd.DataFrame([[os.path.basename(windows_dict['Names'][i]),len(gdf)]],columns=[\"Name\",\"Detections\"])\n",
    "                        proc_df = pd.concat([proc_df,tmp_df],ignore_index=True)\n",
    "                        proc_df.to_csv(proc_csv, index=False)                    #tmp_df['Detections']=len(geoshapes)\n",
    "                        try:\n",
    "                            geoshapes = gpd.read_file(dst_gpkg)                        \n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            geoshapes = None\n",
    "                        geoshapes = geopackager(gdf, i, geoshapes)     \n",
    "\n",
    "                #else:\n",
    "                #    for i in range(len(paths)):\n",
    "                #        tmp_df = pd.DataFrame([[os.path.basename(paths[i]),0]],columns=[\"Name\",\"Detections\"])\n",
    "                #        proc_df = pd.concat([proc_df,tmp_df],ignore_index=True)\n",
    "                #        #proc_df = proc_df.append(tmp_df,ignore_index=True)\n",
    "                #        proc_df.to_csv(proc_csv, index=False)\n",
    "\n",
    "            pbar.update(batch_size)        \n",
    "            stop = datetime.now()\n",
    "        print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = predictions['instances'].pred_masks.cpu().numpy()\n",
    "len(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CP = CustomPredictor(cfg)\n",
    "from detectron2.engine import DefaultPredictor\n",
    "CP = DefaultPredictor(cfg)\n",
    "JOBS=psutil.cpu_count(logical=False)\n",
    "with tqdm(total=len(images),\n",
    "             desc = 'Generating Images',\n",
    "             unit='File') as pbar:\n",
    "    start = datetime.now()\n",
    "    gdf_list = []\n",
    "    for d in range(len(chunks)):\n",
    "    #for d in range(1):\n",
    "        chunk = list(chunks[d])\n",
    "\n",
    "        lambda_f = lambda element:element not in proc_df['Name'].to_list()\n",
    "        #lambda_f = lambda element:element not in geoshapes['Name'].to_list()\n",
    "        filtered = filter(lambda_f, chunk)\n",
    "\n",
    "        chunk = list(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0\n",
    "chunk = list(chunks[d])\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [image_path+'/'+ele for ele in chunk]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_images = [rio.open(img_path) for img_path in paths]\n",
    "#imgs = [reshape_as_image(image.read()) for image in open_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = chunk[0]\n",
    "oxt = 'tiff'\n",
    "from rasterio.windows import Window\n",
    "from rasterio.enums import Resampling\n",
    "imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imgs)):\n",
    "    predictions = CP(imgs[i])\n",
    "    masks = predictions['instances'].pred_masks.cpu().numpy()           \n",
    "    if len(masks)>0:                \n",
    "        for i in range(len(predictions)):\n",
    "            gdf = pred2shape(predictions, paths[i], open_images[i],classes, JOBS, out_dir, i)    \n",
    "            gdf_list.append(gdf)\n",
    "            tmp_df = pd.DataFrame([[os.path.basename(paths[i]),len(gdf)]],columns=[\"Name\",\"Detections\"])\n",
    "            proc_df = pd.concat([proc_df,tmp_df],ignore_index=True)\n",
    "            proc_df.to_csv(proc_csv, index=False)                    #tmp_df['Detections']=len(geoshapes)\n",
    "            try:\n",
    "                geoshapes = gpd.read_file(dst_gpkg)                        \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                geoshapes = None\n",
    "            geoshapes = geopackager(gdf, i, geoshapes)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_crs = open_images[0].crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(masks)>0:                \n",
    "    for i in range(len(predictions)):\n",
    "        gdf = pred2shape(predictions, paths[i], open_images[i],classes, JOBS, out_dir, i)    \n",
    "        gdf_list.append(gdf)\n",
    "        tmp_df = pd.DataFrame([[os.path.basename(paths[i]),len(gdf)]],columns=[\"Name\",\"Detections\"])\n",
    "        proc_df = pd.concat([proc_df,tmp_df],ignore_index=True)\n",
    "        proc_df.to_csv(proc_csv, index=False)                    #tmp_df['Detections']=len(geoshapes)\n",
    "        try:\n",
    "            geoshapes = gpd.read_file(dst_gpkg)                        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            geoshapes = None\n",
    "        geoshapes = geopackager(gdf, i, geoshapes)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoshapes.crs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
